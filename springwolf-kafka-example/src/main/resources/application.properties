import pandas as pd
import yaml
import numpy as np
import boto3
import io
import gh_methods

def load_config(config_path):
    with open(config_path, "r") as file:
        return yaml.safe_load(file)

def load_model_metadata(metadata_path):
    with open(metadata_path, "r") as file:
        return yaml.safe_load(file)

def get_cut_points(metadata):
    return metadata['cut_points']  # Ajuste conforme a estrutura do seu metadata

def download_file_from_s3(bucket_name, file_key):
    s3 = boto3.client('s3')
    response = s3.get_object(Bucket=bucket_name, Key=file_key)
    return pd.read_csv(io.BytesIO(response['Body'].read()))

def upload_file_to_s3(bucket_name, file_key, dataframe):
    csv_buffer = io.StringIO()
    dataframe.to_csv(csv_buffer, index=False)
    s3 = boto3.client('s3')
    s3.put_object(Bucket=bucket_name, Key=file_key, Body=csv_buffer.getvalue())

def process_inference_data(df, score_column, transformation_function, transformation_params):
    df[score_column] = transformation_function(df[score_column], **transformation_params)
    return df

def main():
    # Carregar metadados do modelo
    metadata = load_model_metadata("path/to/model_metadata.yml")
    
    # Carregar configurações do usuário
    config = load_config("path/to/config.yml")
    calculation_type = config["calculation_type"]
    
    # Obter pontos de corte para o cálculo
    cut_points = get_cut_points(metadata)

    # Preparar a função de transformação e parâmetros
    transformation_function, transformation_params = gh_methods.get_transformation_params(calculation_type, cut_points)

    # Definir bucket e caminhos
    bucket_name = 'your-bucket-name'  # Substitua pelo nome do seu bucket
    input_file_key = 'path/to/inference_output.csv'  # Caminho do arquivo de entrada no bucket
    output_file_key = 'path/to/transformed_output.csv'  # Caminho do arquivo de saída no bucket

    # Baixar os dados de inferência do S3
    df = download_file_from_s3(bucket_name, input_file_key)

    # Processar os dados de inferência
    df_transformed = process_inference_data(df, "score", transformation_function, transformation_params)
    
    # Salvar os dados transformados de volta no S3
    upload_file_to_s3(bucket_name, output_file_key, df_transformed)

if __name__ == "__main__":
    main()
