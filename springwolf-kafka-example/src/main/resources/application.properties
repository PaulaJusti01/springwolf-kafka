import pandas as pd
import yaml
import os

def load_config(config_path):
    with open(config_path, 'r') as file:
        return yaml.safe_load(file)

def load_model_metadata(model_metadata_path):
    with open(model_metadata_path, 'r') as file:
        return yaml.safe_load(file)

def calculate_cut_points(model_metadata):
    # A chave que cont√©m os pontos de corte deve ser definida de acordo com o formato dos metadados
    return model_metadata['cut_points']

def read_output_in_chunks(output_path, chunksize):
    for chunk in pd.read_csv(output_path, chunksize=chunksize):
        yield chunk

def apply_calculation(scores, cut_points):
    return pd.cut(scores, bins=cut_points, labels=np.arange(1, len(cut_points)))

def save_chunk_to_output(chunk, output_dir, chunk_index):
    output_file_path = os.path.join(output_dir, f'output_chunk_{chunk_index}.csv')
    chunk.to_csv(output_file_path, index=False)

def main(config_path, output_path, model_metadata_path, output_dir, chunksize):
    config = load_config(config_path)
    model_metadata = load_model_metadata(model_metadata_path)
    cut_points = calculate_cut_points(model_metadata)

    for chunk_index, chunk in enumerate(read_output_in_chunks(output_path, chunksize)):
        scores = chunk['score']
        transformed_scores = apply_calculation(scores, cut_points)
        chunk['score'] = transformed_scores
        save_chunk_to_output(chunk, output_dir, chunk_index)

if __name__ == "__main__":
    # Substitua os caminhos abaixo pelos caminhos corretos
    config_path = 'path/to/config.yml'
    output_path = 'path/to/output.csv'
    model_metadata_path = 'path/to/model_metadata.yml'
    output_dir = 'path/to/output_directory'
    chunksize = 1000  # Por exemplo, 1000 linhas por chunk

    main(config_path, output_path, model_metadata_path, output_dir, chunksize)
