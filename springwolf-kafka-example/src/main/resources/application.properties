import os
import boto3
import yaml
import pandas as pd
from itau_mr7_drp_lotus_internals import apply_transformation  # Nome atualizado da biblioteca

# Definindo constantes para os caminhos dos buckets e do arquivo de configuração
S3_BUCKET_MODEL_METADATA = "seu-bucket-model-metadata"
S3_BUCKET_INFERENCE_OUTPUT = "seu-bucket-inference-output"
S3_BUCKET_TRANSFORMED_OUTPUT = "seu-bucket-transformed-output"
CONFIG_PATH = "caminho/para/seu/config.yml"

# Inicializa o cliente S3
s3_client = boto3.client("s3")

# Carrega os metadados do modelo em memória
def load_model_metadata():
    metadata_key = "model_metadata.yaml"  # Nome do arquivo no bucket S3
    metadata_object = s3_client.get_object(Bucket=S3_BUCKET_MODEL_METADATA, Key=metadata_key)
    metadata_content = metadata_object['Body'].read().decode('utf-8')
    metadata = yaml.safe_load(metadata_content)
    return metadata

# Carrega o parâmetro de cálculo do config.yml do usuário
def load_config():
    with open(CONFIG_PATH, 'r') as file:
        config = yaml.safe_load(file)
    calculation_type = config.get("calculation_type", None)
    if not calculation_type:
        raise ValueError("Parâmetro 'calculation_type' não encontrado no config.yml.")
    return calculation_type

# Processa o arquivo de inferência em chunks e aplica a transformação
def process_inference_output():
    # Carrega os metadados do modelo e o parâmetro de cálculo
    metadata = load_model_metadata()
    calculation_type = load_config()

    # Configurações para chunks
    inference_key = "inference_output.csv"
    transformed_key = "transformed_output/"
    chunk_size = 10000  # Ajuste conforme necessário

    # Realiza o download e processamento do arquivo de inferência
    inference_object = s3_client.get_object(Bucket=S3_BUCKET_INFERENCE_OUTPUT, Key=inference_key)
    inference_df = pd.read_csv(inference_object['Body'], chunksize=chunk_size)

    for i, chunk in enumerate(inference_df):
        # Aplica a transformação usando a biblioteca
        score_column = "score"
        transformed_chunk = apply_transformation(
            chunk, 
            score_column=score_column, 
            transformation_function=calculation_type,  # Passa o tipo de cálculo
            metadata=metadata
        )

        # Salva o chunk transformado em um novo diretório no bucket
        transformed_chunk_key = f"{transformed_key}part_{i}.csv"
        transformed_chunk_csv = transformed_chunk.to_csv(index=False)
        s3_client.put_object(
            Bucket=S3_BUCKET_TRANSFORMED_OUTPUT, 
            Key=transformed_chunk_key, 
            Body=transformed_chunk_csv
        )

if __name__ == "__main__":
    process_inference_output()
